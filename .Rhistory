theArray
theArray[1,,]
theUrl<- "http://www.jaredlander.com/data/Tomato%20First.csv"
tomato <- read.table(file=theUrl, header=TRUE,sep=",")
head(tomato)
tomato
tomato
theUrl
head(tomato)
print(1:10)
theMatrix <- matrix(1:9,nrow=3)
theMatrix
apply(theMatrix, 1, sum)
apply(theMatrix, 2, sum)
rowSums(theMatrix)
colSums(theMatrix)
theMatrix[2,1] <- NA
theMatrix
apply(theMatrix, 1, sum)
apply(theMatrix, 1, sum, na.rm = TRUE)
rowSums(theMatrix)
rowSums(theMatrix, na.rm = TRUE)
theList <- list(A = matrix(1:9, 3), B=1:5, C= matrix(1:4,2),D=2)
theList
lapply(theList, sum)
slapply(theList, sum)
sapply(theList, sum)
theNames <- c("Jared", "Deb", "Paul")
theNames
lapply(theNames, nchar)
sapply(theNames, nchar)
require(ggplot2)
data(diamonds)
head(diamond)
head(diamonds)
diamonds
head(diamonds)
aggregate(price ~ diamonds, mean)
aggregate(price ~ cut, diamonds, mean)
aggregate(price ~ cut, diamonds, sum)
aggregate(price ~ cut + color, diamonds, sum)
aggregate(cbind(price, carat) ~ cut + color, diamonds, sum)
require(plyr)
head(baseball)
baseball
baseball$sf
baseball$sf[baseball$year < 1954]
baseball$sf[baseball$year < 1954] <- 0
baseball$sf[baseball$year < 1954]
any(is.na(baseball$sf))
baseball$hbp
baseball$hbp[is.na(baseball$hbp)]
baseball$hbp[is.na(baseball$hbp)] <- 0
baseball$hbp[is.na(baseball$hbp)]
any(is.na(baseball$hbp))
baseball <- baseball[baseball$ab >= 50,]
basebasll
baseball
baseball$OBP <- with(baseball, (h+bb+hbp)/(ab + bb+hbp+sf))
tail(baseball)
require(data.table)
diamondDT <- data.table(diamonds)
install.packages("data.table")
require(data.table)
diamondDT <- data.table(diamonds)
diamondDT
diamonds
diamondDT
theDT[1:2,]
diamondDT[1:2,]
tables()
rnorm(n = 10)
rnorm(n=10, mean = 100, sd = 20)
randNorm<-rnorm(30000)
randNorm
randDensity <- dnorm(randNorm)
randDensity
require(ggplot2)
ggplot(data.frame(x = randNorm, y = randDensity))
ggplot(data.frame(x = randNorm, y = randDensity)) + aes(x = x, y = y) + geom_point() + labs(x = "Random Normal Variables", y = "Density")
pnorm(randNorm10)
randNorm10 <- rnorm(10)
pnorm(randNorm10)
pnorm(0)
pnorm(c(-3,0,3))
pnorm(3)
pnorm(3) - pnorm(-3)
ggplot(data.frame(x = randNorm, y = randDensity)) + aes(x = x, y = y) + geom_line() + labs(x = "Random Normal Variables", y = "Density")
ggplot(data.frame(x = randNorm, y = randDensity)) + aes(x = x, y = y) + geom_point() + labs(x = "Random Normal Variables", y = "Density")
p <- ggplot(data.frame(x = randNorm, y = randDensity)) + aes(x = x, y = y) + geom_line() + labs(x = "x", y ="Density")
p
neg1Seq <- seq(from=min(randNorm), to=-1,by=.1)
neg1Seq
lessThanNeg1 <- data.frame(xneg1Seq, y=dnorm(neg1Seg))
lessThanNeg1 <- data.frame(x=neg1Seq, y=dnorm(neg1Seg))
lessThanNeg1 <- data.frame(x=neg1Seq, y=dnorm(neg1Seq))
lessThanNeg1
lessThanNeg1 <- rbind(c(min(random),0),lessThanNeg1, c(max(lessThanNeg1$x),0))
lessThanNeg1 <- rbind(c(min(randNorm),0),lessThanNeg1, c(max(lessThanNeg1$x),0))
lessThanNeg1
p+geom_polygon(data=lessThanNeg1, aes(x=x,y=y))
neg1Pos1Seg <- seq(from=-1, to=1,by=.1)
neg1Pos1Seg
neg1To1 <- data.frame(x=neg1Pos1Seq, y= dnorm(neg1Pos1Seq))
neg1Pos1Seq <- neg1Pos1Seg
neg1To1 <- data.frame(x=neg1Pos1Seq, y= dnorm(neg1Pos1Seq))
neg1To1
neg1To1 <- rbind(c(min(neg1To1$x),0),neg1To1, c(max(neg1To1$x),0))
neg1To1
p+geom_polygon(data=neg1To1, aes(x=x,y=y))
randProb <= pnorm(randNorm)
randProb <- pnorm(randNorm)
randProb
ggplot(data.frame(x=randNorm, y=randProb)) + aes(x=x,y=y) + geom_point() + labs(x="Random Normal Variables", y="Probability")
tail(randProb)
x<- sample(x=1:100, size = 100, replace=TRUE)
x
mean(x)
y <- x
y
y[sample(x=1:100, size=20, replace=FALSE)] <-NA
y
mean(y)
mean(y, na.rm=TRUE)
grades <-c(95,72,87,66)
weights <- c(1/2, 1/4,1/8,1/8)
mean(grades)
weighted.mean(x=grades, w=weights)
var(x)
sum((x-mean(x))^2)/(length(x)-1)
sqrt(var(x))
sd(x)
sd(y)
sd(y, na.rm=TRUE)
min(x)
max(x)
median(x)
min(y)
min(y, na.rm=TRUE)
summary(x)
summary(y)
quantile(x, probs=c(0.25,0.75))
quantile(y, probs=c(0.25,0.75))
quantile(y, probs=c(0.25,0.75),na.rm=TRUE)
require(ggplot2)
head(economics)
cor(economics$pce, economics$psavert)
cor(economics[,c(2,4:6)])
GGally::ggpairs(economics[, c(2,4:6)], params=list(labelSize = 8))
install.packages("GGally")
GGally::ggpairs(economics[, c(2,4:6)], params=list(labelSize = 8))
require(reshape2)
require(scales)
ecoCor<- cor(economics[,c(2,4:6)])
ecoCor
econMelt<-melt(ecoCor, varnames=c("x","y"),value.name="Correlation")
econMelt
econMelt <- econMelt[order(econMelt$Correlation),]
econMelt
ggplot(econMelt, aes(x=x, y=y)) + geom_tile(aes(fill=Correlation))+scale_fill_gradient2(low=muted("red"),mid="white",high="steelblue",guide=guide.colorbar(ticks=FALSE,barheight=10),limits=c(-1,1)) + theme_minimal() + labs(x=NULL, y=NULL)
install.packages("GUIDE")
ggplot(econMelt, aes(x=x, y=y)) + geom_tile(aes(fill=Correlation))+scale_fill_gradient2(low=muted("red"),mid="white",high="steelblue",guide=guide.colorbar(ticks=FALSE,barheight=10),limits=c(-1,1)) + theme_minimal() + labs(x=NULL, y=NULL)
require(reshape2)
ggplot(econMelt, aes(x=x, y=y)) + geom_tile(aes(fill=Correlation))+scale_fill_gradient2(low=muted("red"),mid="white",high="steelblue",guide=guide.colorbar(ticks=FALSE,barheight=10),limits=c(-1,1)) + theme_minimal() + labs(x=NULL, y=NULL)
require(scales)
ggplot(econMelt, aes(x=x, y=y)) + geom_tile(aes(fill=Correlation))+scale_fill_gradient2(low=muted("red"),mid="white",high="steelblue",guide=guide.colorbar(ticks=FALSE,barheight=10),limits=c(-1,1)) + theme_minimal() + labs(x=NULL, y=NULL)
ggplot(econMelt, aes(x=x, y=y)) + geom_tile(aes(fill=Correlation))+scale_fill_gradient(low=muted("red"),mid="white",high="steelblue",guide=guide.colorbar(ticks=FALSE,barheight=10),limits=c(-1,1)) + theme_minimal() + labs(x=NULL, y=NULL)
ggplot(econMelt, aes(x=x, y=y)) + geom_tile(aes(fill=Correlation))+scale_fill_gradient2(low=muted("red"),mid="white",high="steelblue",guide=guide.colorbar(ticks=FALSE,barheight=10),limits=c(-1,1)) + theme_minimal() + labs(x=NULL, y=NULL)
ggplot(econMelt, aes(x=x, y=y))
ggplot(econMelt, aes(x=x, y=y)) + geom_tile(aes(fill=Correlation))
ggplot(econMelt, aes(x=x, y=y)) + geom_tile(aes(fill=Correlation))+scale_fill_gradient2(low=muted("red"),mid="white",high="steelblue",guide=guide.colorbar(ticks=FALSE,barheight=10),limits=c(-1,1))
ggplot(econMelt, aes(x=x, y=y)) + geom_tile(aes(fill=Correlation))+scale_fill_gradient(low=muted("red"),mid="white",high="steelblue",guide="colorbar",limits=c(-1,1))
ggplot(econMelt, aes(x=x, y=y)) + geom_tile(aes(fill=Correlation))+scale_fill_gradient(high = "red", low = "white", guide = "colorbar",limits=c(-1,1))
ggplot(econMelt, aes(x=x, y=y)) + geom_tile(aes(fill=Correlation))+scale_fill_gradient(high = "steelblue", mid = "white", low="red", guide = "colorbar",limits=c(-1,1))
ggplot(econMelt, aes(x=x, y=y)) + geom_tile(aes(fill=Correlation))+scale_fill_gradient2(low=muted("red"),mid="white",high="steelblue",guide=guide.colorbar(ticks=FALSE,barheight=10),limits=c(-1,1)) + theme_minimal() + labs(x=NULL, y=NULL)
ggplot(econMelt, aes(x=x, y=y)) + geom_tile(aes(fill=Correlation))+scale_fill_gradient2(low=muted("red"),mid="white",high="steelblue",guide="colourbar",limits=c(-1,1)) + theme_minimal() + labs(x=NULL, y=NULL)
data(tips, package="reshape2")
head(tips)
GGally::ggpairs(tips)
require(RXKCD)
install.packages("RXKCD")
require(RXKCD)
getXKCD(which="552")
head(tips)
unique(tips$sex)
unique(tips$day)
t.test(tips$tip, alternative="two.sided", mu=2.5)
randT <- rt(3000, dg=NROW(tips)-1)
randT <- rt(3000, df=NROW(tips)-1)
randT
tipTTest <- t.test(tips$tips, alternative="two.sided",mu=2.5)
tipTTest <- t.test(tips$tip, alternative="two.sided",mu=2.5)
ggplot(data.frame(x=randT))+geom_density(aes(x=x),fill="grey",color="grey")+geom_vline(xintercept=tipTTest$statistic)+geom_vline(xintercept=mean(randT) + c(-2,2)*sd(randT), linetype=2)
t.test(tips$tip, alternative="greater",mu=2.5)
t.test(tips$tip, alternative="greater",mu=2.9)
t.test(tips$tip, alternative="greater",mu=3)
install.packages("KernSmooth")
library(kernsmooth)
library(KernSmooth)
library("RCurl")
library("rjson")
library("RCurl")
library("rjson")
# Accept SSL certificates issued by public Certificate Authorities
options(RCurlOptions = list(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl")))
h = basicTextGatherer()
hdr = basicHeaderGatherer()
req = list(
Inputs = list(
"input1" = list(
"ColumnNames" = list("Age", "Workclass", "Fnlwgt", "Education", "Education-num", "Marital-status", "Occupation", "Relationship", "Race", "Sex", "Capital-gain", "Capital-lass", "Hours-per-week", "Native-country", "Income"),
"Values" = list( list( "0", "value", "0", "value", "0", "value", "value", "value", "value", "value", "0", "0", "0", "value", "value" ),  list( "0", "value", "0", "value", "0", "value", "value", "value", "value", "value", "0", "0", "0", "value", "value" )  )
)                ),
GlobalParameters = setNames(fromJSON('{}'), character(0))
)
body = enc2utf8(toJSON(req))
api_key = "jH6rIL+WPxXtr+w6qdjRe/YeliQy6xxrY+YWU6kWwV7ZlRi3hlPIjBkCsq3r22i844BAr9DaFFwtwgDdiCcR6w==" # Replace this with the API key for the web service
authz_hdr = paste('Bearer', api_key, sep=' ')
h$reset()
curlPerform(url = "https://ussouthcentral.services.azureml.net/workspaces/167f42db598c4cdfa64e9787b654b82a/services/bb62699785d645169dddee6029ad1d57/execute?api-version=2.0&details=true",
httpheader=c('Content-Type' = "application/json", 'Authorization' = authz_hdr),
postfields=body,
writefunction = h$update,
headerfunction = hdr$update,
verbose = TRUE
)
headers = hdr$value()
httpStatus = headers["status"]
if (httpStatus >= 400)
{
print(paste("The request failed with status code:", httpStatus, sep=" "))
# Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure
print(headers)
}
print("Result:")
result = h$value()
print(fromJSON(result))
library("RCurl")
library("rjson")
# Accept SSL certificates issued by public Certificate Authorities
options(RCurlOptions = list(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl")))
h = basicTextGatherer()
hdr = basicHeaderGatherer()
req = list(
Inputs = list(
"input1" = list(
"ColumnNames" = list("Age", "Workclass", "Fnlwgt", "Education", "Education-num", "Marital-status", "Occupation", "Relationship", "Race", "Sex", "Capital-gain", "Capital-lass", "Hours-per-week", "Native-country", "Income"),
"Values" = list( list( "52", "self-emp-not-inc", "209642", "HS-grad", "12", "Married-civ-spouse", "Exec-managerial", "Husband", "White", "Male", "0", "0", "45", "United-States", "0"  ),  list( "0", "value", "0", "value", "0", "value", "value", "value", "value", "value", "0", "0", "0", "value", "value" )  )
)                ),
GlobalParameters = setNames(fromJSON('{}'), character(0))
)
body = enc2utf8(toJSON(req))
api_key = "jH6rIL+WPxXtr+w6qdjRe/YeliQy6xxrY+YWU6kWwV7ZlRi3hlPIjBkCsq3r22i844BAr9DaFFwtwgDdiCcR6w==" # Replace this with the API key for the web service
authz_hdr = paste('Bearer', api_key, sep=' ')
h$reset()
curlPerform(url = "https://ussouthcentral.services.azureml.net/workspaces/167f42db598c4cdfa64e9787b654b82a/services/bb62699785d645169dddee6029ad1d57/execute?api-version=2.0&details=true",
httpheader=c('Content-Type' = "application/json", 'Authorization' = authz_hdr),
postfields=body,
writefunction = h$update,
headerfunction = hdr$update,
verbose = TRUE
)
headers = hdr$value()
httpStatus = headers["status"]
if (httpStatus >= 400)
{
print(paste("The request failed with status code:", httpStatus, sep=" "))
# Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure
print(headers)
}
print("Result:")
result = h$value()
print(fromJSON(result))
Auto=read.table("Auto.data",header=T,na.strings="?")
fix(Auto)
setwd("C:/StanfordOnline")
Auto=read.table("Auto.data",header=T,na.strings="?")
fix(Auto)
lm.fit=lm(mpg~horsepower,  Auto)
lm.fit
summary(lm.fit)
39.935861 - 0.157845 * 98
plot(horsepower,mpg)
attach(Auto)
plot(horsepower,mpg)
abline(lm.fit,pch=20,col=red)
abline(lm.fit,pch=20,col="red")
plot(lm.fit)
plot(predict(lm.fit),rstudent(lm.fit))
par(mfrow=c(2,2))
plot(lm.fit)
plot(preict(lm.fit),residuals(lm.fit))
plot(predict(lm.fit),residuals(lm.fit))
plot(predict(lm.fit),rstudent(lm.fit))
plot(hatvalues(lm.fit))
which.max(hatvalues(lm.fit))
Auto
par(mfrow=c(2,2))
plot(lm.fit)
predict(lm.fit, data.frame(horsepower=c(98)), interval="confidence")
sd(c(5,8,12))
which.min(c(4,1,6))
ls()
rm(ls())
ls()
rm(ls())
rm(ls(),)
rm(ls)
setwd("C:/edx/MITx15.071x")
WHO=load.csv("WHO.csv")
str(WHO)
ls()
setwd("C:/edx/MITx15.071x")
ls()
WHO=load.csv("WHO.csv")
str(WHO)
ls()
ls()
setwd("C:/edx/MITx15.071x")
ls()
WHO=load.csv("WHO.csv")
install.packages("load.csv")
?load.csv
?load.csv()
WHO=read.csv("WHO.csv")
str(WHO)
summary(WHO$Over60)
which.min(WHO$Over60)
WHO[183,]
which.max(WHO$LiteracyRate)
WHO[44,]
tapply(WHO$ChildMortality,WHO$Region,mean)
CHICAGO=read.csv("mvtWeek1.csv")
str(CHICAGO)
which.max(CHICAGO$ID)
max(CHICAGO$ID)
min(CHICAGO$Beat)
summary(CHICAGO)
nrow(subset(CHICAGO,Arrest==TRUE))
CHICAGO[1,]$Date
CHICAGO$Date[1]
Summary(CHICAGO)
summary(CHICAGO)
str(CHICAGO)
DateConvert=as.Date(strptime(CHICAGO$Date,"%m/%d/%y %H:%M"))
summary(DateConvert)
CHICAGO$Month=months(DateConvert)
CHICAGO$Weekday=weekdays(DateConvert)
CHICAGO$Date=DateConvert
table(CHICAGO$Month)
which.min(table(CHICAGO$Month))
table(CHICAGO$Weekday)
which.min(table(CHICAGO$Weekday))
which.max(table(CHICAGO$Weekday))
table(CHICAGO$Month,CHICAGO$Arrest)
table(CHICAGO$Arrest,CHICAGO$Month)
hist(CHICAGO$Date,breaks=100)
hist(CHICAGO$Date,breaks=15)
hist(CHICAGO$Date,breaks=14)
plot(CHICAGO$Date,CHICAGO$Arrest)
plot(CHICAGO$Arrest,CHICAGO$Date)
plot(CHICAGO,CHICAGO$Date)
boxplot(CHICAGO,CHICAGO$Date)
boxplot(CHICAGO$Date)
boxplot(CHICAGO$Arrest, CHICAGO$Date)
boxplot(CHICAGO$Arrest, las=2)
boxplot(CHICAGO, CHICAGO$Date)
boxplot(CHICAGO$ID, CHICAGO$Date)
boxplot(CHICAGO$Arrest, CHICAGO$Date)
boxplot(Arrest~Date,data=CHICAGO)
boxplot(Arrest~Date,data=CHICAGO)
boxplot(Date~Arrest,data=CHICAGO)
hist(CHICAGO[CHICAGO$Arrest==TRUE,],breaks=14)
hist(CHICAGO[CHICAGO$Arrest==TRUE,]$Date,breaks=14)
boxplot(Date~Arrest,data=CHICAGO)
CHICAGO=read.csv("mvtWeek1.csv")
str(CHICAGO)
summary(CHICAGO)
max(CHICAGO$ID)
min(CHICAGO$Beat)
nrow(subset(CHICAGO,Arrest==TRUE))
summary(CHICAGO)
CHICAGO[1,]$Date
CHICAGO$Date[1]
DateConvert=as.Date(strptime(CHICAGO$Date,"%m/%d/%y %H:%M"))
summary(DateConvert)
Years(DateConvert)
years(DateConvert)
year(DateConvert)
Year(DateConvert)
as.Date(DateConvert,"%y")
as.numeric(DateConvert,"%Y")
CHICAGO$Month=months(DateConvert)
CHICAGO$Weekday=weekdays(DateConvert)
CHICAGO$Date=DateConvert
table(CHICAGO$Month)
which.min(table(CHICAGO$Month))
table(CHICAGO$Weekday)
which.max(table(CHICAGO$Weekday))
table(CHICAGO$Arrest,CHICAGO$Month)
hist(CHICAGO$Date,breaks=14)
hist(CHICAGO[CHICAGO$Arrest==TRUE,]$Date,breaks=14)
boxplot(Date~Arrest,data=CHICAGO)
table(CHICAGO$Arrest,CHICAGO$Date)
table(CHICAGO$Arrest,CHICAGO$Year)
summary(CHICAGO$Arrest)
2152/15536
nrow(subset(CHICAGO,Arrest==TRUE))
2152/(18517 + 2152)
1212/(1212+13068)
550/(550+13542)
sort(table(CHICAGO$LocationDescription))
table(CHICAGO$LocationDescription
)
sort(table(CHICAGO$LocationDescription))
subset(CHICAGO,LocationDescription=='STREET'|LocationDescription==' PARKING LOT/GARAGE(NON.RESID.)')
summary(subset(CHICAGO,LocationDescription=='STREET'|LocationDescription==' PARKING LOT/GARAGE(NON.RESID.)'))
summary(subset(CHICAGO,LocationDescription=='STREET'|LocationDescription=='PARKING LOT/GARAGE(NON.RESID.)'))
summary(subset(CHICAGO,LocationDescription=='STREET'))
summary(subset(CHICAGO,LocationDescription=='STREET')$LocationDescription)
nrow(subset(CHICAGO,LocationDescription=='STREET'))
nrow(CHICAGO)
nrow(subset(CHICAGO,LocationDescription=='STREET' | LocationDescription=='PARKING LOT/GARAGE(NON.RESID.)'))
sort(table(CHICAGO$LocationDescription))
nrow(subset(CHICAGO,LocationDescription=='STREET' | LocationDescription=='PARKING LOT/GARAGE(NON.RESID.)'| LocationDescription=='ALLEY'|LocationDescription=='GAS STATION'|LocationDescription=='GAS STATION'|LocationDescription='DRIVEWAY - RESIDENTIAL'))
nrow(subset(CHICAGO,LocationDescription=='STREET' | LocationDescription=='PARKING LOT/GARAGE(NON.RESID.)'| LocationDescription=='ALLEY'|LocationDescription=='GAS STATION'|LocationDescription=='GAS STATION'|LocationDescription='DRIVEWAY - RESIDENTIAL'))
nrow(subset(CHICAGO,LocationDescription=='STREET' | LocationDescription=='PARKING LOT/GARAGE(NON.RESID.)'| LocationDescription=='ALLEY'|LocationDescription=='GAS STATION'|LocationDescription='DRIVEWAY - RESIDENTIAL'))
nrow(subset(CHICAGO,LocationDescription=='STREET' | LocationDescription=='PARKING LOT/GARAGE(NON.RESID.)'| LocationDescription=='ALLEY'|LocationDescription=='GAS STATION'|LocationDescription=='DRIVEWAY - RESIDENTIAL'))
156564+14852+2308+2111+1675
Top5=subset(CHICAGO,LocationDescription %in% TopLocations)
TopLocations = c("STREET", "PARKING LOT/GARAGE(NON.RESID.)", "ALLEY", "GAS STATION", "DRIVEWAY - RESIDENTIAL")
Top5=subset(CHICAGO,LocationDescription %in% TopLocations)
summary(Top5)
table(Top5$LocationDescription)
Top5$LocationDescription = factor(Top5$LocationDescription)
table(Top5$LocationDescription)
str(Top5)
table(Top5$Arrest,Top5$LocationDescription)
11595/(11595+144969)
table(Top5$LocationDescription,Top5$Arrest)
table(GAS$WeekDay)
GAS=subset(Top5,LocationDescription=="GAS STATION")
table(GAS$WeekDay)
table(GAS$WeekDays)
summary(GAS$WeekDays)
summary(GAS$Weekday)
table(GAS$Weekday,GAS$Arrest)
table(Top5$LocationDescription,Top5$Weekday)
rm(gas)
rm(GAS)
getwd()
USDA = read.csv("USDA.csv")
str(USDA)
summary(USDA)
USDA$Sodium
# Finding the index of the food with highest sodium levels
which.max(USDA$Sodium)
# Get names of variables in the dataset
names(USDA)
# Get the name of the food with highest sodium levels
USDA$Description[265]
# Create a subset of the foods with sodium content above 10,000mg
HighSodium = subset(USDA, Sodium>10000)
# Count the number of rows, or observations
nrow(HighSodium)
# Output names of the foods with high sodium content
HighSodium$Description
# Finding the index of CAVIAR in the dataset
match("CAVIAR", USDA$Description)
# Find amount of sodium in caviar
USDA$Sodium[4154]
# Doing it in one command!
USDA$Sodium[match("CAVIAR", USDA$Description)]
# Summary function over Sodium vector
summary(USDA$Sodium)
# Standard deviation
sd(USDA$Sodium, na.rm = TRUE)
# Video 4 - Plots
# Scatter Plots
plot(USDA$Protein, USDA$TotalFat)
# Add xlabel, ylabel and title
plot(USDA$Protein, USDA$TotalFat, xlab="Protein", ylab = "Fat", main = "Protein vs Fat", col = "red")
# Creating a histogram
hist(USDA$VitaminC, xlab = "Vitamin C (mg)", main = "Histogram of Vitamin C")
# Add limits to x-axis
hist(USDA$VitaminC, xlab = "Vitamin C (mg)", main = "Histogram of Vitamin C", xlim = c(0,100))
hist(USDA$VitaminC)
hist(USDA$VitaminC, xlab = "Vitamin C (mg)", main = "Histogram of Vitamin C", xlim = c(0,100), breaks=100)
hist(USDA$VitaminC, xlab = "Vitamin C (mg)", main = "Histogram of Vitamin C", xlim = c(0,100), breaks=2000)
# Boxplots
boxplot(USDA$Sugar, ylab = "Sugar (g)", main = "Boxplot of Sugar")
# Video 5 - Adding a variable
# Creating a variable that takes value 1 if the food has higher sodium than average, 0 otherwise
HighSodium = as.numeric(USDA$Sodium > mean(USDA$Sodium, na.rm=TRUE))
str(HighSodium)
# Adding the variable to the dataset
USDA$HighSodium = as.numeric(USDA$Sodium > mean(USDA$Sodium, na.rm=TRUE))
# Similarly for HighProtein, HigCarbs, HighFat
USDA$HighCarbs = as.numeric(USDA$Carbohydrate > mean(USDA$Carbohydrate, na.rm=TRUE))
USDA$HighProtein = as.numeric(USDA$Protein > mean(USDA$Protein, na.rm=TRUE))
USDA$HighFat = as.numeric(USDA$TotalFat > mean(USDA$TotalFat, na.rm=TRUE))
# Video 6 - Summary Tables
# How many foods have higher sodium level than average?
table(USDA$HighSodium)
# How many foods have both high sodium and high fat?
table(USDA$HighSodium, USDA$HighFat)
# Average amount of iron sorted by high and low protein?
tapply(USDA$Iron, USDA$HighProtein, mean, na.rm=TRUE)
# Maximum level of Vitamin C in hfoods with high and low carbs?
tapply(USDA$VitaminC, USDA$HighCarbs, max, na.rm=TRUE)
# Using summary function with tapply
tapply(USDA$VitaminC, USDA$HighCarbs, summary, na.rm=TRUE)
